{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\kcgad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (23.1.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\kcgad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('API_KEY')\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "\tmessages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\tresponse = openai.ChatCompletion.create(\n",
    "\t\tmodel=model,\n",
    "\t\tmessages=messages,\n",
    "\t\ttemperature=0\n",
    "\t)\n",
    "\treturn response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "\tf = open(filename, 'r')\n",
    "\treturn f.read()\n",
    "\n",
    "def generate_prompt_text(prompt_file, text_file):\n",
    "    prompt = read_file(prompt_file)\n",
    "    text = read_file(text_file)\n",
    "\n",
    "    output = prompt + \"```\" + text + \"```\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "1 - Jack and Jill go on a quest to fetch water from a hilltop well, but misfortune strikes as Jack trips and tumbles down the hill with Jill following suit, yet they return home slightly battered but with undimmed adventurous spirits.\n",
      "\n",
      "2 - జాక్ మరియు జిల్ ఒక ఆనందమైన పిల్లలు అయినా విలేజ్ లో నీరు తీసుకునే కోసం ఒక పర్వతం మీద వెళ్లారు, కానీ జాక్ ఒక కలువ మీద పడి జిల్ అక్కడ తన పాదములతో పడింది, కానీ వాళ్ళు స్లైట్లీ బ్యాటర్డ్ అయినా తిరిగి వచ్చారు, మరియు వాళ్ళ స్పర్ధల ఆనందంతో కొనసాగించారు.\n",
      "\n",
      "3 - జాక్, జిల్\n",
      "\n",
      "4 - {\n",
      "    \"telugu_summary\": \"జాక్ మరియు జిల్ ఒక ఆనందమైన పిల్లలు అయినా విలేజ్ లో నీరు తీసుకునే కోసం ఒక పర్వతం మీద వెళ్లారు, కానీ జాక్ ఒక కలువ మీద పడి జిల్ అక్కడ తన పాదములతో పడింది, కానీ వాళ్ళు స్లైట్లీ బ్యాటర్డ్ అయినా తిరిగి వచ్చారు, మరియు వాళ్ళ స్పర్ధల ఆనందంతో కొనసాగించారు.\",\n",
      "    \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "prompt_file_path = 'prompts.txt'  # Path to the file containing prompts\n",
    "text_file_path = 'texts.txt'  # Path to the file containing texts\n",
    "\n",
    "prompt = generate_prompt_text(prompt_file_path, text_file_path)\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)\n",
    "# Now you can use the prompt and text to feed into your language model for further processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
